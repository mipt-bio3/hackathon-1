# **Распознавание речи и эмоций в аудиопротоколах телемедицинских консультаций**
## **Описание**
Решение позволяет получать текстовые расшифровки телемедицинских консультаций с автоматическим аннотированием эмоций для последующего анализа с помощью больших языковых моделей (LLM).

Входные данные: аудиозапись (аудиопротокол).

Выходные данные: текстовая расшифровка с аннотированными эмоциями.

Формат:<br />
*— Текстовая расшифровка фразы* [(1) (2)]<br />
(1) тип эмоции (с наибольшей вероятностью)<br />
(2) значение вероятности<br />

Пример получаемого результата:

>— Доктор, я съел пиццу вместе с коробкой. Я умру? [страх 0.80]<br />
>— Мы все умрём. [нейтрально 0.92]<br />
>— Что я наделал… [грусть 0.74]<br />

## **Применяемые модели**
* GigaAM (GigaAcoustic Model) — класс открытых моделей для обработки звучащей речи. И её дообученные состояния для распознавания русскоязычной речи (GigaAM-CTC) и для определения эмоций (GigaAM-Emo)
* pyannote.audio — набор инструментов, предобученных моделей и пайплайнов для задач диаризации (сегментации и разделения дикторов)

## **Принцип работы**
1. Аудиозапись сегментируется с помощью pyannote.audio [опционально]
2. Каждый сегмент транскрибируется с помощью GigaAM-CTC
3. Для каждого сегмента выполняется классификация эмоций с помощью GigaAM-Emo
4. Транскрипция аннотируется: указывается тип эмоции с наибольшей вероятностью и само значение вероятности

## **Структура проекта**
* colab/
  * eda/ - EDA для датасетов
  * inference/ - примеры использования моделей
* info/ - информация о моделях и датасетах
* samples/ - примеры аудиофайлов
* solution/ - решение + демо

## **Запуск**
Используйте Jupyter Notebook: solution/solution_demo.ipynb

## **Варианты применения**
- оценка эмоционального состояния медицинского персонала
- оценка удовлетворенности пациента
- мониторинг "острых состояний", автоматическое определение конфликтных ситуаций
- аналитика записей разговоров для улучшения качества работы колл-центра, оценка операторов
- предложение дополнительных услуг
